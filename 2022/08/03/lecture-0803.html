
<hr />
<p>toc: true
comments: true
layout: post
description: CS224W Lecture 8.
categories: [Graph Neural Network, GNN, Graph Convolution Network, GCN ]
title: Lecture 8.3 - Setting up GNN Prediction Tasks
—</p>

<h2 id="3-setting-up-gnn-prediction-tasks">3) Setting up GNN Prediction Tasks</h2>

<p><img src="https://imgur.com/UZP5j0O" alt="Imgur" /></p>

<p>이제 모델 학습을 위해서 데이터를 어떻게 나눠야할지 배워봅시다.</p>

<ul>
  <li>
    <p>train / validation / test 데이터셋으로 어떻게 분류하면 좋을까요?</p>
  </li>
  <li>그래프 데이터는 우리가 기존에 배운 split 방식과는 <strong>조금 다르게 배분</strong>합니다.</li>
  <li>
    <p>그 이유는, 이미지의 경우, 데이터 단위가 이미지 한 장이고, 각 이미지는 서로 영향을 미치지 않지만, 그래프의 구조는 다양하고, 각 데이터 포인트 간의 영향이 제각각 다르기 때문입니다.</p>

    <p>e.g) 예를 들어서, 노드 5를 예측하기 위해서는 노드 1, 2, 4, 6이 필요한데, 5번이 test, 4,6 번이 validation에 사용되면 데이터 유실(Data Leakage)이 발생함.</p>
  </li>
  <li>그렇다면 어떻게??</li>
</ul>

<p><img src="https://imgur.com/mQ6S3lk" alt="Imgur" /></p>

<p><strong>방법1)  Transductive setting</strong></p>

<p>인풋 그래프를 모든 데이터셋 종류에 포함시킵니다. (train/valid/test)</p>

<ul>
  <li>노드 라벨만 나눕니다.</li>
  <li>학습 시, 그래프 전체를 사용해서 임베딩을 계산하고, 1번과 2번의 라벨만을 학습에 사용합니다.(나머지 라벨 포함 X)</li>
  <li>검증 시, 그래프 전체를 사용해서 임베딩하고, 3,4번의 라벨만 평가에 사용합니다.</li>
  <li>
    <p>node, edge prediction 태스크에서만 사용 가능합니다.</p>

    <p><img src="https://imgur.com/YCy91Tw" alt="Imgur" /></p>
  </li>
</ul>

<p><strong>방법2) Inductive setting</strong></p>

<p>데이터셋 종류에 따라 엣지 연결을 끊고 각기 다른 그래프로 취급합니다.</p>

<p>e.g) Train : {1,2} Validation : {3,4}, Test : {5,6}</p>

<ul>
  <li>그래프 간 연결된 엣지들을 끊고, 각 다른 그래프로 취급하기 때문에, 5번 노드는 더 이상 1번 노드의 영향을 받지 않습니다.</li>
  <li>node, edge, graph 태스크에서 다 사용 가능합니다.</li>
</ul>

<p><img src="https://imgur.com/vaZI9uo" alt="Imgur" /></p>

<p>헷갈림 방지. train/val/test 그래프는 각각 다른 그래프.</p>

<h3 id="graph-classification">Graph Classification</h3>

<ul>
  <li>이 경우 inductive setting을 사용해야합니다. 학습 시 보지 못한 그래프를 추론해야하기 때문입니다.</li>
</ul>

<h3 id="link-prediction">Link Prediction</h3>

<ul>
  <li>숨겨진 엣지들에 대해서 추론합니다.</li>
  <li>unsupervised / self-supervised</li>
  <li>고의적으로 몇몇 edge들을 숨기고, 모델이 예측할 수 있도록 학습!</li>
</ul>

<p><img src="https://imgur.com/oTUr3t8" alt="Imgur" /></p>

<p><img src="https://imgur.com/JCll7Di" alt="Imgur" /></p>

<p>message edges : 학습에 사용되는 엣지들</p>

<p>supervision edges : 학습에 사용되지 않은 숨겨진 엣지들</p>

<p><strong>step1.</strong> 원본 그래프에 message와 supervision 엣지들을 나눕니다.</p>

<p><strong>step2.</strong> train/validation/test set 별로 엣지들을 나눕니다.</p>

<p><strong>옵션 1 : inductive link prediction split</strong></p>

<ul>
  <li>서로 다른 message edge와 supervision 조합을 갖는 데이터셋들</li>
</ul>

<p><img src="https://imgur.com/ZTXzWKt" alt="Imgur" /></p>

<p><strong>옵션 2 : transductive link prediction split</strong></p>

<ul>
  <li>보편적인 link prediction 방법</li>
  <li>‘transductive’의 정의상 그래프 전체가 인풋으로 들어가는 게 맞지만,</li>
  <li><strong>엣지들은 그래프 구조 중 일부이면서도 지도 역할을 하기 때문에</strong>, validation과 test 시에 노출을 보류(hold out)할 필요가 있습니다.</li>
  <li>학습 시, training set을 위해 supervision edges들을 보류(hold out)할 필요가 있습니다.</li>
</ul>

<p><img src="https://imgur.com/dzpxu00" alt="Imgur" /></p>

<p>그림에서와 같이, train, validation, test 단계별로 엣지 수가 증가하는데,</p>

<ul>
  <li>학습 후, supervision edges들은 GNN에 이미 노출된 상황</li>
  <li>그래서 이상적인 모델에서는 검증 시, supervision edges들을 학습에 사용해야하기 때문입니다.</li>
  <li>테스트 상황에서도 마찬가지입니다.</li>
</ul>

<p><img src="https://imgur.com/iYxPXm0" alt="Imgur" /></p>

<p><img src="https://imgur.com/UZP5j0O" alt="Imgur" /></p>

<p>💡Takeaway</p>

<p><img src="https://imgur.com/9LXIZPN" alt="Imgur" /></p>
