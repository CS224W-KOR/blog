{
  
    
        "post0": {
            "title": "Lecture 4.4 - Matrix Factorization and Node Embeddings",
            "content": "Embeddings &amp; Matrix Factorization . Connection to Matrix Factorization . Matrix Factorization . RandomWalk-based Similarity . Limitations . Algorithms 정리 .",
            "url": "https://cs224w-kor.github.io/blog/matrix/pagerank/spider%20trap/2022/07/13/lecture-0404.html",
            "relUrl": "/matrix/pagerank/spider%20trap/2022/07/13/lecture-0404.html",
            "date": " • Jul 13, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Lecture 4.3 - Random Walk with Restarts",
            "content": "Recommendation . . Bipartite User-Item Graph . Node proximity Measurements . Node proximity Measurements . Proximity on Graphs .",
            "url": "https://cs224w-kor.github.io/blog/matrix/pagerank/spider%20trap/2022/07/13/lecture-0403.html",
            "relUrl": "/matrix/pagerank/spider%20trap/2022/07/13/lecture-0403.html",
            "date": " • Jul 13, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Lecture 4.2 - PageRank, How to Solve?",
            "content": "이전의 강의에서 Powe iteration 방법으로 반복적인 매트릭스 곱 연산으로 $ mathbf{r}$을 구할 수 있음을 확인했습니다. 이 방법에 대해 조금 더 구체적으로 살펴보겠습니다. . Power Iteration Method . power iteration은 2가지 표현식이 있는데 하나는 벡터의 요소 관점에서의 업데이트 식(왼쪽)과 다른 하나는 매트릭스 관점의 업데이트 식(오른쪽)으로 나타낼 수 있습니다. . . 과정을 살펴보면 다음과 같습니다. . 처음 초기화로 모든 노드의 importance score를 똑같은 값으로 만들어 줍니다.(반복적인 연산으로 수렴을 보장하므로 사실 어떤 값으로 초기화하든 상관없습니다.) $ boldsymbol{r}^{(0)}=[1 / N, ldots ., 1 / N]^{T}$ | 반복적인 연산을 하면서 $ mathbf{r}$ 값을 업데이트합니다. $ boldsymbol{r}^{(t+1)}= boldsymbol{M} cdot boldsymbol{r}^{(t)}$ | 수렴조건 $ left | boldsymbol{r}^{( boldsymbol{t}+ mathbf{1})}- boldsymbol{r}^{(t)} right | _{1}&lt; varepsilon$을 만족할 때까지 2번 과정의 연산을 진행합니다. | . | 예시 그래프에서의 power iteration 과정은 다음과 같습니다. . . . Three Questions . Does this converge? 반복적인 연산과정을 통해 값이 수렴하는가? | Does it converge to what we want? 수렴한 값이 우리가 원하는 값인가? | Are results reasonable? 연산 결과가 합당한가?(말이 되는가?) | (어색한 한국어 번역보다 영어로된 질문에서 얻어가는 insight가 좋을 것 같습니다.) . Problems . PageRank에는 2가지의 문제가 있습니다. . Dead Ends | out-link를 가지지 않는 일부 페이지(노드)들에서 생기는 문제로 이런 페이지들에서 importance가 leak out 됩니다. leak out의 세어나가다 라는 뜻 그대로 importance flow의 흐름에서 값이 세어나가는 문제를 말합니다. . 아래의 예시에서 페이지 b에서 나가는 out-link가 없다보니 importance update를 한 결과가 $r_a = 0, r_b=0$이 됨을 확인할 수 있습니다. 이는 앞서 page rank $ mathbf{r}$ vector의 정의에서 약속한 모든 노드의 importance의 합이 1이 된다는 column stochastic 수학적 전제에서 벗어난 결과 입니다. . . Spider traps | 그래프의 모든 out-link들이 빠져나갈 곳이 없는 순환구조를 이룰 때 발생합니다. 결국 spider trap 페이지가 모든 importance 값을 독차지하게 됩니다. . 아래의 예시에서 a에서 walk를 시작하더라고 b로 이동한 후 b에서 빠져나올 수 없습니다. 이런 경우 importance update 결과 모든 importance를 페이지 b가 가지게 되어 $r_a = 0, r_b=1$이 됩니다. 이런 경우 페이지 a에 아무리 큰 웹 그래프가 연결되어 있다고 하더라도 이동할 수 없습니다. 사실 spider trap은 column stochastic을 만족하기 때문에 수학적으로 문제되진 않습니다. 하지만 우리가 원하지 않는 값에 수렴하는 문제로 볼 수 있습니다. . . Solutions . 위의 2가지 문제들 모두 Teleports로 해결할 수 있습니다. . Dead Ends를 Teleports로 해결하기 | . Spider Traps를 Teleports로 해결하기 | . The Google Matrix . rj=∑i→jβridi+(1−β)1Nr_{j}= sum_{i rightarrow j} beta frac{r_{i}}{d_{i}}+(1- beta) frac{1}{N}rj​=i→j∑​βdi​ri​​+(1−β)N1​ . G=βM+(1−β)[1N]N×NG= beta M+(1- beta) left[ frac{1}{N} right]_{N times N}G=βM+(1−β)[N1​]N×N​ . Random Teleports ($ beta$=0.8) . . Solving PageRank 정리 . PageRank $ mathbf{r} = mathbf{G} mathbf{r}$을 power iteration method로 풀 수 있다. | PageRank에서 생길 수 있는 문제들인 Dead Ends와 Spider Traps를 Random Uniform Teleportation으로 해결할 수 있다. | .",
            "url": "https://cs224w-kor.github.io/blog/matrix/pagerank/spider%20trap/2022/07/13/lecture-0402.html",
            "relUrl": "/matrix/pagerank/spider%20trap/2022/07/13/lecture-0402.html",
            "date": " • Jul 13, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Lecture 4.1 - PageRank",
            "content": "Lecture 4. Graph as Matrix . 4강에서는 Graph를 매트릭스(선형대수) 관점으로 바라보는 것에 대해 이야기 합니다. . . 다음 3가지 키워드, Random walk(Node Importance), Matrix Factorization, Node embedding를 중심으로 공부합니다. 강의는 총 4파트로 나누어져 진행됩니다. . Lecture 4.1 - PageRank | Lecture 4.2 - PageRank, How to Solve? | Lecture 4.3 - Random Walk with Restarts | Lecture 4.4 - Matrix Factorization and Node Embeddings | . . The Web as a Directed Graph . . 웹을 거시적인 관점으로 보게되면, 하나의 웹 페이지 → Node로 하이퍼링크 → Edge로 생각하여 하나의 거대한 Graph로 볼 수 있습니다. . Side issue . 다이나믹하게 새로 페이지들이 생길 수 있습니다. | 다크웹과 같은 접근할 수 없는 페이지들도 있을 수 있습니다. | . 잠시 Side issue는 내려놓고, 새로 페이지들이 생기지도 않고 기존의 페이지들이 사라지지도 않는 Static pages 상황을 가정해봅시다. 아래의 그림에서처럼 페이지들은 하이퍼링크들로 서로 연결되어 있고, 유저는 페이지들에 달려있는 하이퍼 링크들로 이루어진 연결망을 기반으로 항해하듯이 Navigational 하게 page to page 이동을 하게 됩니다. (오늘날에는 post, comment, like 등의 기반의 transactional한 웹에서의 상호작용이 일어나지만 이는 우선 논외로 하겠습니다.) . . 위의 그림처럼 웹 그래프는 방향성이 있는 유향 그래프(Directed graph)임을 알 수 있습니다. 위키피디아와 같은 웹 사전 페이지들 간의 관계성이나 논문의 인용 관계 그래프 등에서 예시를 쉽게 찾아볼 수 있습니다. . . Ranking Nodes on the Graph . 웹을 하나의 거대한 유향 그래프로 생각할 때 한가지 중요한 insight가 있습니다. . 💡 모든 웹 페이지들이 똑같이 중요하지는 않다 . 바로 각 페이지의 중요성이 똑같지 않다는 이야기는 그래프에서 각 노드의 중요성(importance)가 다르다는 말로 바꿔 생각할 수 있습니다. 아래 사진을 보면 직관적으로 파란색 노드가 빨간색 노드보다 더 중요할 것 같다라고 생각할 수 있습니다. 왜 그렇게 보일까요? 아직 노드의 중요성에 대해 정의하지 않았지만 그래프에서 각 노드를 중심으로 뻗어있는 edge(link)의 수가 한눈에 비교되기 때문에 직관적으로 파악할 수 있는 것입니다. 이처럼 웹 그래프의 link structure를 가지고 우리는 각 페이지들(node)의 ranking을 매길 수 있습니다. . . Link Analysis Algorithms . 각 페이지들의 중요성(importance)를 파악하기 위해 Link Analysis가 필요합니다. . 본 수업에서 다룰 Link Analysis 알고리즘들은 아래 총 3개에 대해서 다룰 예정입니다. . PageRank | Personalized PageRank (PPR) | Random Walk with Restarts | . Links as Votes . 링크가 투표용지라고 생각해봅시다. 여기서 유향 그래프인 웹 그래프에서 링크는 2가지 종류가 있다는 것을 다시한번 생각해봐야 합니다. . in-comming links(in-links): 기준 페이지로 들어오는 방향의 링크 | out-going links(out-links): 기준 페이지에서 나가는 방향의 링크 | . 이렇게 방향까지 고려하여 링크를 투표라고 생각할 때, 엄밀히 말하자면 in-link를 투표라고 생각해야 할 것 입니다. 한 가지 더 생각해볼 문제는 모든 in-link들을 동등하게 생각할 수 있는가?라는 문제입니다. 어떤 링크들은 다른 링크들에 비해 좀 더 중요한 페이지로부터(from) 기준페이지로(to) 온 링크일 수도 있기 때문에 count에 차등을 둬야 하지 않을까라고 생각할 수도 있습니다. 이런 고민들은 결국 페이지들이 서로 연결되어 있어서 recursive한 문제로 볼 수 있습니다. . ➕ recursive한 문제란, 물리고 물리는 문제로 생각할 수 있습니다. A→B 링크에서 A가 중요한 페이지라는 사실을 기반으로 B가 중요해지고, 이어지는 B→C 링크에서 이 영향을 이어받아 C까지 중요한 페이지라고 판단하게 되기 때문입니다. PageRank . The “Flow” Model . 위에서 설명한 recursive한 특성을 기반으로 중요성이 흘러가는(flow) 모델을 생각해볼 수 있습니다. 중요성을 $r$이라는 변수로 두고 기준 노드 j의 importance가 어떻게 flow되는지 살펴보겠습니다. . j로 in-link되어있는 i, k 의 importance $r_i$, $r_k$를 각 노드의 out-link의 수만큼 나누어서 j로 전달됩니다. i 노드의 out-link는 총 3개 이므로 $ frac{r_i}{3}$, k노드의 out-link는 총 4개 이므로 $ frac{r_k}{4}$로 계산되어 두 값의 합이 $r_j$가 됩니다. | $r_j$는 j노드의 out-link를 통해 flow하게 되는데 out-link의 수, 즉 3으로 나누어져 $ frac{r_j}{3}$ 값이 각각의 다음 노드들로 $r_j$값이 전달되게 됩니다. | . 이처럼 importance가 높은 페이지로부터 in-link된 페이지는 영향을 받아 importance가 높아짐을 알 수 있습니다. 노드 $j$의 rank, $r_j$를 정의하면 다음과 같이 수식으로 나타낼 수 있습니다. (이때 $d_i$는 노드 i의 out-degree를 말합니다.) . rj=∑i→jridir_{j}= sum_{i rightarrow j} frac{r_{i}}{d_{i}}rj​=i→j∑​di​ri​​ . 다음과 같은 예시에서 각 기준 노드를 가지고 in-link들을 고려하여 “Flow equation”을 계산해보면 다음과 같다. . . |노드 y |노드 a|노드 m| |-|-|-| |y에서 오는 링크 + a에서 오는 링크|y에서 오는 링크 + m에서 오는 링크|a에서 오는 링크| |ry=ry2+ra2r_y = frac{r_y}{2} + frac{r_a}{2}ry​=2ry​​+2ra​​|ra=ry2+rmr_a = frac{r_y}{2} + r_mra​=2ry​​+rm​|rm=ra2r_m = frac{r_a}{2}rm​=2ra​​| . ➕ 3 Unknowns, 3 Equations 이기 때문에 4번째 constraint로 $r_y + r_a + r_m =1$로 scale관련 constraint를 추가하여 Gaussian elimination을 사용하여 선형방정식으로 풀려고 하는 생각은 좋지 않다. 왜냐하면 importance는 이런식으로 scalable하지 않기 때문이다. (It’s not scalable) 좀 더 정교한 설계가 필요하다. Matrix Formulation . Stochastic Adjacency Matrix $ mathbf{M}$ . $ mathbf{M}$은 $(node의 수) times (node의 수)$차원의 매트릭스 입니다. | $i$→$j$ 링크에서 매트릭스 요소 $M_{ji}$는 $ frac{1}{d_i}$가 됩니다. ($d_i$를 노드 $i$의 out-degree라고 정의합니다.) . Mji=1diM_{ji} = frac{1}{d_i}Mji​=di​1​ 오른쪽 예시에서처럼 노드 $i$를 기준으로 총 3개의 out-link들이 있다면 각각의 값은 $1/3$이 됩니다. . | column 기준 stochastic : 열 방향의 모든 값들을 더하면 1이 되는 확률값이 됩니다. | . . Rank Vector $r$ . $ mathbf{r}$은 각 페이지의 entry 값을 가지는 $(node의 수) times 1$ 차원의 벡터입니다. | 각 페이지의 importance score를 $r_i$로 정의합니다. | 모든 노드의 importance score의 합은 1입니다. 따라서 이 또한 확률값으로 생각할 수 있습니다. | . ∑iri=1 sum_ir_i = 1i∑​ri​=1 . Flow Equations . 이전에 정의했던 노드의 rank 수식을 새롭게 정의한 매트릭스 $M$과 벡터 $r$로 다시 써보면 Flow Equation을 완성할 수 있습니다. . r=M⋅r mathbf{r}= mathbf{M} cdot mathbf{r}r=M⋅r . 앞서 살펴본 간단한 그래프 예시를 가져와서 flow equation을 매트릭스 연산으로 표현해보면 아래와 같습니다. (flow equation은 앞내용을 참고) . . . Connection to Random Walk . 다음과 같은 조건을 만족하며 랜덤하게 웹페이지들을 돌아다니고 있는 유저를 생각해보겠습니다. . 시점 $t$에 페이지 $i$에 있습니다. | 다음 시점 $t+1$에 페이지 $i$로부터 나가는 방향의 out-link들 중에 uniform하게 선택하여 서핑을 합니다. | 앞서 선택된 out-link를 통해 $i$와 연결된 $j$ 페이지에 도달합니다. | 이 과정(1~3)을 무한으로 반복합니다. | . 여기에서 우리는 시점 의 개념을 고려하여 새로운 개념 정의를 하나 할 수 있습니다. . p(t) mathbf{p(t)}p(t) . $ mathbf{p(t)}$는 확률 벡터(probability distribution)로, 이 벡터의 $i$번째 요소는 앞서 가정한 유저가 시점 $t$에 페이지 $i$에 있을 확률을 나타냅니다. . The Stationary Distribution . 앞서 정의한 $ mathbf{p(t)}$를 가지고 이 유저가 시점 $t+1$에 있을 확률분포는 다음과 같이 계산합니다. . p(t+1)=M⋅p(t) mathbf{p(t+1)}= mathbf{M} cdot mathbf{p(t)}p(t+1)=M⋅p(t) . 💡 만약에 유저가 웹 서핑을 계속하다가 $ mathbf{p(t+1)} = mathbf{p(t)}$ 같은 상황이 되면 어떨까요? . p(t+1)=M⋅p(t)=p(t) mathbf{p(t+1)}= mathbf{M} cdot mathbf{p(t)} = mathbf{p(t)}p(t+1)=M⋅p(t)=p(t) . 이러한 상황에서는 더 이상 유저가 특정 페이지에 있을 확률이 변하지 않고 유지되는 경우가 되며, 이를 stationary distribution of a random walk 라고 합니다. . 이러한 형태는 낮설지가 않은데, 앞서 rank vector $ mathbf{r}$가 매트릭스 $ mathbf{M}$과 flow equation을 구성할 때 이러한 꼴이었으며, 따라서 $ mathbf{r}$은 stationary distribution of a random walk 입니다. . Eigenvector Formulation . 이전 Lecture 2에서 잠시 배웠던 eigenvector와 eignvalue를 생각해보면 다음 수식을 떠올려볼 수 있습니다. . λc=Ac lambda mathbf{c} = mathbf{A} mathbf{c}λc=Ac . 여기에서 flow equation을 다시 위와 같은 꼴로 작성해보면, 아래와 같이 eigenvalue가 1이고 eigenvector가 $ mathbf{r}$인 수식으로 해석될 수 있습니다. . 1⋅r=M⋅r1 cdot mathbf{r}= mathbf{M} cdot mathbf{r}1⋅r=M⋅r . 따라서 $ mathbf{r}$은 매트릭스 $ mathbf{M}$의 principle eigenvector(eigenvalue 1)이며, 임의의 벡터 $ mathbf{u}$에서 시작해서 계속 매트릭스 $ mathbf{M}$을 곱하여 극한 $ mathbf{M}( mathbf{M}(…( mathbf{M}( mathbf{M} mathbf{u}))))$으로 도달하게되는 long-term distribution이 됩니다. 이러한 방식으로 $ mathbf{r}$을 구하는 방법을 Power iteration 이라고 합니다. . PageRank 정리 . 웹 구조에서 볼 수 있는 link들을 기반으로 node들의 importance를 측정할 수 있다. | 랜덤하게 웹 서핑하는 유저 모델은 stochastic advacency matrix $ mathbf{M}$으로 나타낼 수 있다. | PageRank 수식은 $ mathbf{r} = mathbf{M} mathbf{r}$ 이며, $ mathbf{r}$은 (1) 매트릭스 $ mathbf{M}$의 principle eigenvector, (2) stationary distribution of a random walk 2가지로 해석될 수 있다. | . Original Lecture Video : [CS224W: Machine Learning with Graphs | 2021 | Lecture 4.1 - PageRank](https://youtu.be/TU0ankRcHmo) | .",
            "url": "https://cs224w-kor.github.io/blog/matrix/pagerank/spider%20trap/2022/07/13/lecture-0401.html",
            "relUrl": "/matrix/pagerank/spider%20trap/2022/07/13/lecture-0401.html",
            "date": " • Jul 13, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Lecture 1",
            "content": "lecture 1 . 1.1 - Why Graphs . 그래프란? . ⇒ a general language for describing and analyzing entities with relations/interactions . ⇒ 서로 관계/상호작용하는 entity들을 설명하고 분석하기 위한 언어라고 할 수 있음 . (여기서 entity란 정보의 세계에서 의미있는 하나의 정보 단위) . 그래프 예시 event graphs | computer networks | disease pathways | food webs | particle networks | underground networks | social networks | economic networks | communication networks | citation networks | internet | networks of neurons | knowledge graphs | regulatory networks | scene graphs | code graphs | molecules | 3D shapes | . | . ⇒ 그래프로 세상에 일어나는 모든 현상과 구조들을 설명할 수 있다(broadly applicable). . (관심있는 분야의 현상을 그래프로 표현하여 딥러닝 모델 구조로 변환할 수 있는 능력이 있다면…) . e.g) 분자 구조, 3D 이미지 모형(voxel), 먹이사슬, 소셜 네트워크 등 . (graph와 network의 차이?) . 그래프에서 얻을 수 있는 정보 유형 . 데이터 포인트 간의 구성(organization)과 연결 | 유사한 데이터 포인트 간의 밀접성(similarity) | 데이터 포인트 간의 연결들이 이루는 그래프 구조 | . 그래프가 갖는 구조를 어떻게 활용해 나은 예측을 할 수 있을까? . ⇒ 현상을 명시적(explicitly)으로 잘 반영한 그래프 모델링이 중요하다! . 그래프 ML이 더 어려운 이유? . ⇒ arbitrary size and complex topology . ⇒ spatial locality(공간 지역성)가 없다 . ⇒ 이미지나 텍스트 인풋의 경우 어느 한 데이터포인트로부터 다른 데이터 포인트 간 상대적 위치가 정해져있다(e.g 상하좌우). 하지만, 그래프의 경우 축이 되는 데이터 포인트가 존재하지 않는다. . 그래프를 사용한 딥러닝 . ⇒ 인풋으로는 그래프를 받고, 아웃풋으로는 아래와 같은 형식(ground truth도 동일한 형식)이 가능하다. . node-level | edge-level | graph/subgraph generation | graph/subgraph classification | . 그래프 딥러닝 모델에서 우리가 바라는 플로우 . . 위 플로우를 거친 좋은 성능의 모델을 만들기 위해서는, 인풋이 현상을 잘 반영한 embedding vector로 변환될 수 있도록 학습하는 것이 중요하다.(Representation Learning) . 코스 과정동안 배울 그래프 방법들 traditional methods : graphlets, graph kernels | node embeddings : DeepWalk, Node2Vec | Graph Neural Networks : GCN, GraphSAGE, GAT, Theory of GNNs | Knowledge graphs and reasoning : TransE, BetaE | Deep Generative Models for graphs | Applications | . | . 1.2 - Applications of Graph ML . 그래프 ML은 다양한 태스크 커버가 가능하다 . Node Level(node classification) | . example1) protein folding (구글의 알파폴드) . 배경 : 단백질은 아미노산으로 이루어져있는데, 복잡한 3D 입체 구조의 아미노산 연결 때문에 단백질 구조를 파악하는 태스크는 많게는 1-2년까지 걸린다고 함. | key idea : spatial graph graph : 단백질 | nodes : 아미노산 | edges : 사슬구조 | . | . Edge Level | . example1) Recommender system (PinSage) . nodes : users and items | edges : user-item interactions . . | . example2) drugs and side effects . nodes : drugs &amp; proteins | edges : interaction | . using 2 heterogeneous graphs(drugs &amp; proteins) . . ⇒ drug A와 B를 함께 썼을 때, 생길 수 있는 interaction(edge)는 무엇인가? . Community(subgraph) level | . example1) Traffic Prediction . nodes : Road Segments(도로 구간) | edges : 도로 구간 교차점 | . . ⇒ 아웃풋 : 도착 예정 시간 . Graph-level prediction | . 4-1) graph classification . example1) drug discovery . nodes : atoms | edges : chemical bonds | graph : molecules | . ⇒ 노드와 에지 정보를 통해 그래프(분자) 예측 . 4-2 ) Graph-level generation . example1) drug generation . nodes : atoms | edges : chemical bonds | graph : moelcules | . ⇒ 새로운 그래프(분자) 생성 . example2) physics simulation (graph evolution) . nodes : particles | edges : interaction between particles | . ⇒ t시점 전의 정보로 t시점 이후의 그래프 생성 . . 1.3 - Choice of Graph . 그래프 구성요소 . . objects : nodes, vertices . Interactions : links, edges . system : network, graph . **object와 interactions로 이루어진 데이터 구조 ⇒ graph . 그래프로 세상에 일어나는 모든 현상과 구조들을 설명할 수 있다(broadly applicable). . . 표현법에 따라 그래프의 활용방법은 무궁무진하다. 중요한 것은 적절한 표현을 선택하는 것. | 설명하고자하는 현상을 그래프로 정의하고 싶다면, 먼저 아래 두가지 질문을 하자. what are nodes? | what are edges? | | . Directed vs Undirected Graphs . . ‘페이스북의 친구와 인스타그램의 팔로우’는 directed와 undirected graph를 이해하기에 좋은 예이다. . Node Degrees (차수) . undirected graph undirected graph의 경우, node degree는 해당 노드에 연결된 에지의 총 갯수 | average degree는 연결된 에지의 총 갯수 곱하기 2(쌍방향 연결이기 때문)를 그래프를 이루는 전체 노드 수로 나눈 값 | . | directed graph directed graph의 경우, 해당 노드로 향하는 in-degree와 해당 노드로부터 뻗어나가는 out-degree로 나눌 수 있다. node degree는 이 in-degree와 out-degree의 합. | . | . Bipartite Graph . . 자주 등장하는 또다른 그래프의 종류는 bipartite graph(이분 그래프)이다. | 이분 그래프는 2개의 집합 U와 V의 interaction을 나타낸 그래프이다. U와 V는 서로 독립적인 집합이며, 같은 집합의 원소끼리는 연관되지 않는다. e.g) A와 B 간 연결X | 이분 그래프의 예로는 구매자-구매 아이템 관계 등이 있다. | . Folded/Projected Bipartite Graph . Bipartite 그래프에서 집합 간의 요소들 간의 상관관계가 명시되어있다면 Folded 또는 Projected Bipartite Graph라고 부른다. | . (정보에 depth가 생긴다는 의미에서 folded라고 붙인듯하다.) . . Adjacency Matrix . . 그래프의 노드 간 연결관계(edge)를 나타낸 매트릭스이다. | 각 행과 열은 노드의 번수를 의미하고, 0은 연결되지 않음, 1은 연결됨을 의미한다. 만약 3번째 행에 4번째 열이 1이라면, 3번 노드와 4번 노드는 연결되어있음을 의미한다. | undirect graph라면, 주대각선을 기준으로 adj matrix는 대칭이고, directed graph라면, 대칭이 아닐 수도 있다. | adjacency matrix는 컴퓨터가 그래프를 이해할 수 있는 형태이지만, 문제는 노드의 수가 수백개에서 수십만개로 늘어나고, 많은 노드들의 연결이 몇 개 없을 때, 메모리 사이즈에 비해 0인 값이 너무 많게되는 문제(sparse)가 발생한다. | . Edge List . . Edge List는 그래프를 엣지들의 리스트로 나타낸 값이다. | 서로 연결된 노드를 짝지어 리스트에 배열한다. | 그래프가 크고 sparse할 때 유용하다. | . Node and Edge Attributes . ⇒ 노드와 엣지로 나타낼 수 있는 값들은 어떤 것들이 있을까? . ⇒ 그래프에서 어떤 정보들을 얻을 수 있을까? . weight (e.g., frequency of communication) 엣지가 0과 1 이외의 값을 갖는다면? | . . | ranking (best friend, second best friend, …) | type (friend, relative, co-worker) | sign (+ / - ) | properties depending on the structure of the rest of the graph : Number of common friends | . More Types of Graphs . self-edges(self-loops) . . | multigraph . . | Connected(undirected) graph . | . . **연결이 부분적으로만 되어 있어도, 그래프는 adjacency matrix에 표현 가능하다. . . Connectivity of Driected Graphs . Strongly connected directed graph 모든 노드들이 다른 모든 노드들로 방향 상관없이 다다르는 path가 항상 있다면, strongly connected directed graph이다. | . | Weakly connected directed graph 에지 방향을 무시했을 때, 노드 간 전부 연결되어있다면, weakly connected directed graph이다. | . | Strongly connected components(SCC) . . 그래프에 속한 다른 노드들 전부는 아니지만, 해당 그룹 간의 연결이 한 노드에서 다른 노드로 항상 도달할 수 있다면(strong connection)한다면, 그 그룹을 strongly connected components라고 지칭한다. | . | .",
            "url": "https://cs224w-kor.github.io/blog/markdown/2022/07/06/lecture-01.html",
            "relUrl": "/markdown/2022/07/06/lecture-01.html",
            "date": " • Jul 6, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://cs224w-kor.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://cs224w-kor.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Us",
          "content": "안녕하세요. . 소개글을 적는 곳입니다. .",
          "url": "https://cs224w-kor.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://cs224w-kor.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}